{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9724c2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TTNT1\\miniconda3\\envs\\nlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda - Falcon-1B_FTT_IMDB.ipynb:34\n",
      "GPU Name: NVIDIA RTX A5000 - Falcon-1B_FTT_IMDB.ipynb:36\n",
      "VRAM: 25.76 GB - Falcon-1B_FTT_IMDB.ipynb:37\n",
      "Loading IMDB Dataset - Falcon-1B_FTT_IMDB.ipynb:44\n",
      "Cleaning Dataset (Removing URLs & HTML) - Falcon-1B_FTT_IMDB.ipynb:61\n"
     ]
    }
   ],
   "source": [
    "# @title 1. Setup, Load Data & Cleaning\n",
    "# Cài thư viện nếu chưa có (chạy 1 lần)\n",
    "# !pip install transformers datasets evaluate scikit-learn accelerate matplotlib pandas\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import psutil\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "from scipy.special import softmax\n",
    "\n",
    "\n",
    "# Chỉ định chỉ dùng 1 GPU (ví dụ GPU số 0)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# 1. Setup Path (Lưu kết quả ngay tại thư mục chứa file code trên máy)\n",
    "SAVE_PATH = './Falcon_1B_IMDB_Results'\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)\n",
    "\n",
    "# 2. Check Device (Quan trọng cho VS Code local)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device} - Falcon-1B_FTT_IMDB.ipynb:34\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)} - Falcon-1B_FTT_IMDB.ipynb:36\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB - Falcon-1B_FTT_IMDB.ipynb:37\")\n",
    "\n",
    "# Dọn dẹp VRAM cũ\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# 3. Load Dataset\n",
    "print(\"Loading IMDB Dataset - Falcon-1B_FTT_IMDB.ipynb:44\")\n",
    "# Load Full Dataset\n",
    "dataset = load_dataset(\"imdb\") \n",
    "\n",
    "# 4. Clean Text (Chuẩn hóa giống file mẫu)\n",
    "def clean_text(example):\n",
    "    text = example['text']\n",
    "    text = text.lower()\n",
    "    # Xóa URL\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Xóa HTML tags (<br />)\n",
    "    text = re.sub(r'<br\\s*/>', ' ', text)\n",
    "    # Xóa khoảng trắng thừa\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    example['text'] = text\n",
    "    return example\n",
    "\n",
    "print(\"Cleaning Dataset (Removing URLs & HTML) - Falcon-1B_FTT_IMDB.ipynb:61\")\n",
    "dataset = dataset.map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfd44f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Tokenizer: tiiuae/falcon-rw-1b - Falcon-1B_FTT_IMDB.ipynb:5\n",
      "Tokenizing Dataset (Có thể mất vài phút trên máy cá nhân) - Falcon-1B_FTT_IMDB.ipynb:16\n",
      "Splitting Train set into Train/Val - Falcon-1B_FTT_IMDB.ipynb:25\n",
      "Dataset ready: Train(22500), Val(2500), Test(25000) - Falcon-1B_FTT_IMDB.ipynb:32\n"
     ]
    }
   ],
   "source": [
    "# @title 2. Tokenization & Data Splits for Falcon-1b\n",
    "\n",
    "# 1. Load Tokenizer\n",
    "MODEL_NAME = 'tiiuae/falcon-rw-1b'\n",
    "print(f\"Loading Tokenizer: {MODEL_NAME} - Falcon-1B_FTT_IMDB.ipynb:5\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# QUAN TRỌNG: Falcon không có pad_token mặc định, phải gán thủ công\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 2. Tokenize Function\n",
    "def tokenize_function(examples):\n",
    "    # Max length 512, padding max_length để đồng bộ tensor\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "print(\"Tokenizing Dataset (Có thể mất vài phút trên máy cá nhân) - Falcon-1B_FTT_IMDB.ipynb:16\")\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# 3. Format PyTorch\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "# 4. Split Train/Val (90/10)\n",
    "print(\"Splitting Train set into Train/Val - Falcon-1B_FTT_IMDB.ipynb:25\")\n",
    "# IMDB gốc đã có sẵn 'test', ta chỉ chia 'train' thành 'train' và 'val'\n",
    "train_val_split = tokenized_datasets[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "dataset_train = train_val_split[\"train\"]\n",
    "dataset_val = train_val_split[\"test\"]\n",
    "dataset_test = tokenized_datasets[\"test\"]\n",
    "\n",
    "print(f\"Dataset ready: Train({len(dataset_train)}), Val({len(dataset_val)}), Test({len(dataset_test)}) - Falcon-1B_FTT_IMDB.ipynb:32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec8dd9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model: tiiuae/falcon-rw-1b... - Falcon-1B_FTT_IMDB.ipynb:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Some weights of FalconForSequenceClassification were not initialized from the model checkpoint at tiiuae/falcon-rw-1b and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loaded successfully using SafeTensors (BF16). - Falcon-1B_FTT_IMDB.ipynb:32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training (Turbo Mode with BF16 on A5000)... - Falcon-1B_FTT_IMDB.ipynb:89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2112' max='2112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2112/2112 2:52:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>0.132447</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.955574</td>\n",
       "      <td>0.970468</td>\n",
       "      <td>0.941130</td>\n",
       "      <td>0.989965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.157201</td>\n",
       "      <td>0.962000</td>\n",
       "      <td>0.961954</td>\n",
       "      <td>0.968548</td>\n",
       "      <td>0.955449</td>\n",
       "      <td>0.990554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.179790</td>\n",
       "      <td>0.964800</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.967226</td>\n",
       "      <td>0.962609</td>\n",
       "      <td>0.990505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed in: 10376.99 seconds - Falcon-1B_FTT_IMDB.ipynb:95\n",
      "Saving model to ./Falcon_1B_IMDB_Results... - Falcon-1B_FTT_IMDB.ipynb:98\n",
      "Falcon1b Model saved successfully! - Falcon-1B_FTT_IMDB.ipynb:101\n"
     ]
    }
   ],
   "source": [
    "# @title 3. Training Falcon-1b (Optimized for RTX A5000)\n",
    "\n",
    "# 1. Metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "        \n",
    "    probs = softmax(logits, axis=1)[:, 1]\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    \n",
    "    try:\n",
    "        roc_auc = roc_auc_score(labels, probs)\n",
    "    except:\n",
    "        roc_auc = 0.0\n",
    "        \n",
    "    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall, 'roc_auc': roc_auc}\n",
    "\n",
    "# 2. Model Init (Tối ưu cho A5000: Dùng bfloat16)\n",
    "print(f\"Loading Model: {MODEL_NAME}... - Falcon-1B_FTT_IMDB.ipynb:24\")\n",
    "try:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME, \n",
    "        num_labels=2,\n",
    "        torch_dtype=torch.bfloat16,  \n",
    "        use_safetensors=True \n",
    "    )\n",
    "    print(\">>> Loaded successfully using SafeTensors (BF16). - Falcon-1B_FTT_IMDB.ipynb:32\")\n",
    "except Exception as e:\n",
    "    print(f\">>> SafeTensors failed ({e}). Attempting legacy load... - Falcon-1B_FTT_IMDB.ipynb:34\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME, \n",
    "        num_labels=2,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        use_safetensors=False\n",
    "    )\n",
    "\n",
    "model.to(device)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.gradient_checkpointing_enable() \n",
    "\n",
    "# 3. Training Arguments (Cấu hình Turbo cho A5000)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results_falcon',\n",
    "    num_train_epochs=3,\n",
    "    \n",
    "    # --- CẤU HÌNH TỐI ƯU VRAM 24GB ---\n",
    "    per_device_train_batch_size=16,   \n",
    "    gradient_accumulation_steps=2,  \n",
    "    per_device_eval_batch_size=32,    \n",
    "    \n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs_falcon',\n",
    "    logging_steps=10,                 \n",
    "    \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    \n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_total_limit=2,\n",
    "    \n",
    "    # --- QUAN TRỌNG CHO A5000 ---\n",
    "    fp16=False,   \n",
    "    bf16=True,    \n",
    "    \n",
    "    report_to=\"none\",\n",
    "    optim=\"adamw_torch\",\n",
    "    dataloader_num_workers=0,\n",
    ")\n",
    "\n",
    "# 4. Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_val,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "# 5. Start Training\n",
    "print(\"Starting Training (Turbo Mode with BF16 on A5000)... - Falcon-1B_FTT_IMDB.ipynb:89\")\n",
    "start_train_time = time.time()\n",
    "trainer.train()\n",
    "end_train_time = time.time()\n",
    "\n",
    "training_time = end_train_time - start_train_time\n",
    "print(f\"\\nTraining completed in: {training_time:.2f} seconds - Falcon-1B_FTT_IMDB.ipynb:95\")\n",
    "\n",
    "# 6. Save Final Model\n",
    "print(f\"Saving model to {SAVE_PATH}... - Falcon-1B_FTT_IMDB.ipynb:98\")\n",
    "trainer.save_model(SAVE_PATH)\n",
    "tokenizer.save_pretrained(SAVE_PATH)\n",
    "print(\"Falcon1b Model saved successfully! - Falcon-1B_FTT_IMDB.ipynb:101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b180064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Evaluation on Test Set - Falcon-1B_FTT_IMDB.ipynb:4\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== REPORT: Falcon1b (FFT) on IMDB ====== - Falcon-1B_FTT_IMDB.ipynb:34\n",
      "1. Classification Metrics: - Falcon-1B_FTT_IMDB.ipynb:35\n",
      "Accuracy:  0.9625 - Falcon-1B_FTT_IMDB.ipynb:36\n",
      "Precision: 0.9601 - Falcon-1B_FTT_IMDB.ipynb:37\n",
      "Recall:    0.9652 - Falcon-1B_FTT_IMDB.ipynb:38\n",
      "F1Score:  0.9626 - Falcon-1B_FTT_IMDB.ipynb:39\n",
      "ROCAUC:   0.9921 - Falcon-1B_FTT_IMDB.ipynb:40\n",
      "\n",
      "2. Efficiency Metrics: - Falcon-1B_FTT_IMDB.ipynb:42\n",
      "Training Time:      10376.99 s - Falcon-1B_FTT_IMDB.ipynb:43\n",
      "Inference Latency:  21.5771 ms/sample - Falcon-1B_FTT_IMDB.ipynb:44\n",
      "Model Size (Disk):  2501.77 MB - Falcon-1B_FTT_IMDB.ipynb:45\n",
      "Peak RAM Usage:     1592.88 MB - Falcon-1B_FTT_IMDB.ipynb:46\n",
      "Peak VRAM Usage:    7521.45 MB - Falcon-1B_FTT_IMDB.ipynb:47\n",
      "\n",
      "Report saved to ./Falcon_1B_IMDB_Results\\imdb_falcon_results.csv - Falcon-1B_FTT_IMDB.ipynb:65\n"
     ]
    }
   ],
   "source": [
    "# @title 4. Final Evaluation on Test Set & Report\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Running Evaluation on Test Set - Falcon-1B_FTT_IMDB.ipynb:4\")\n",
    "\n",
    "# 1. Classification Metrics\n",
    "start_pred_time = time.time()\n",
    "predictions_output = trainer.predict(dataset_test)\n",
    "end_pred_time = time.time()\n",
    "metrics = predictions_output.metrics\n",
    "\n",
    "# 2. Efficiency Metrics (Đo hiệu năng)\n",
    "total_samples = len(dataset_test)\n",
    "total_inference_time = end_pred_time - start_pred_time\n",
    "latency_per_sample = (total_inference_time / total_samples) * 1000 # đổi sang ms\n",
    "\n",
    "# Tính kích thước Model\n",
    "bin_path = os.path.join(SAVE_PATH, 'pytorch_model.bin')\n",
    "safe_path = os.path.join(SAVE_PATH, 'model.safetensors')\n",
    "\n",
    "if os.path.exists(bin_path):\n",
    "    model_size = os.path.getsize(bin_path) / (1024 * 1024) # MB\n",
    "elif os.path.exists(safe_path):\n",
    "    model_size = os.path.getsize(safe_path) / (1024 * 1024) # MB\n",
    "else:\n",
    "    model_size = 0\n",
    "\n",
    "# Đo RAM/VRAM hiện tại\n",
    "process = psutil.Process(os.getpid())\n",
    "ram_usage = process.memory_info().rss / 1024 ** 2\n",
    "vram_usage = torch.cuda.memory_allocated() / 1024 ** 2 if torch.cuda.is_available() else 0\n",
    "\n",
    "# 3. Print Report\n",
    "print(\"\\n====== REPORT: Falcon1b (FFT) on IMDB ====== - Falcon-1B_FTT_IMDB.ipynb:34\")\n",
    "print(f\"1. Classification Metrics: - Falcon-1B_FTT_IMDB.ipynb:35\")\n",
    "print(f\"Accuracy:  {metrics.get('test_accuracy', 0):.4f} - Falcon-1B_FTT_IMDB.ipynb:36\")\n",
    "print(f\"Precision: {metrics.get('test_precision', 0):.4f} - Falcon-1B_FTT_IMDB.ipynb:37\")\n",
    "print(f\"Recall:    {metrics.get('test_recall', 0):.4f} - Falcon-1B_FTT_IMDB.ipynb:38\")\n",
    "print(f\"F1Score:  {metrics.get('test_f1', 0):.4f} - Falcon-1B_FTT_IMDB.ipynb:39\")\n",
    "print(f\"ROCAUC:   {metrics.get('test_roc_auc', 0):.4f} - Falcon-1B_FTT_IMDB.ipynb:40\")\n",
    "\n",
    "print(f\"\\n2. Efficiency Metrics: - Falcon-1B_FTT_IMDB.ipynb:42\")\n",
    "print(f\"Training Time:      {training_time:.2f} s - Falcon-1B_FTT_IMDB.ipynb:43\")\n",
    "print(f\"Inference Latency:  {latency_per_sample:.4f} ms/sample - Falcon-1B_FTT_IMDB.ipynb:44\")\n",
    "print(f\"Model Size (Disk):  {model_size:.2f} MB - Falcon-1B_FTT_IMDB.ipynb:45\")\n",
    "print(f\"Peak RAM Usage:     {ram_usage:.2f} MB - Falcon-1B_FTT_IMDB.ipynb:46\")\n",
    "print(f\"Peak VRAM Usage:    {vram_usage:.2f} MB - Falcon-1B_FTT_IMDB.ipynb:47\")\n",
    "\n",
    "# 4. Save CSV\n",
    "results_df = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"F1\", \"ROC-AUC\", \"Precision\", \"Recall\", \"Training Time (s)\", \"Inference Latency (ms)\", \"Model Size (MB)\"],\n",
    "    \"Value\": [\n",
    "        metrics.get('test_accuracy', 0),\n",
    "        metrics.get('test_f1', 0),\n",
    "        metrics.get('test_roc_auc', 0),\n",
    "        metrics.get('test_precision', 0),\n",
    "        metrics.get('test_recall', 0),\n",
    "        training_time,\n",
    "        latency_per_sample,\n",
    "        model_size\n",
    "    ]\n",
    "})\n",
    "results_file = os.path.join(SAVE_PATH, 'imdb_falcon_results.csv')\n",
    "results_df.to_csv(results_file, index=False)\n",
    "print(f\"\\nReport saved to {results_file} - Falcon-1B_FTT_IMDB.ipynb:65\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
